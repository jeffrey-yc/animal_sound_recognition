{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'webrtcvad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3cc1f5270e7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mwebrtcvad\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpip\u001b[0m \u001b[0minstall\u001b[0m \u001b[0mwebrtcvad\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m '''\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwebrtcvad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'webrtcvad'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Requirements:\n",
    "+ pyaudio - `pip install pyaudio`\n",
    "+ py-webrtcvad - `pip install webrtcvad`\n",
    "'''\n",
    "import webrtcvad\n",
    "import collections\n",
    "import sys\n",
    "import signal\n",
    "import pyaudio\n",
    "\n",
    "from array import array\n",
    "from struct import pack\n",
    "import wave\n",
    "import time\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK_DURATION_MS = 30       # supports 10, 20 and 30 (ms)\n",
    "PADDING_DURATION_MS = 1500   # 1 sec jugement\n",
    "CHUNK_SIZE = int(RATE * CHUNK_DURATION_MS / 1000)  # chunk to read\n",
    "CHUNK_BYTES = CHUNK_SIZE * 2  # 16bit = 2 bytes, PCM\n",
    "NUM_PADDING_CHUNKS = int(PADDING_DURATION_MS / CHUNK_DURATION_MS)\n",
    "# NUM_WINDOW_CHUNKS = int(240 / CHUNK_DURATION_MS)\n",
    "NUM_WINDOW_CHUNKS = int(400 / CHUNK_DURATION_MS)  # 400 ms/ 30ms  ge\n",
    "NUM_WINDOW_CHUNKS_END = NUM_WINDOW_CHUNKS * 2\n",
    "\n",
    "START_OFFSET = int(NUM_WINDOW_CHUNKS * CHUNK_DURATION_MS * 0.5 * RATE)\n",
    "\n",
    "vad = webrtcvad.Vad(1)\n",
    "\n",
    "pa = pyaudio.PyAudio()\n",
    "stream = pa.open(format=FORMAT,\n",
    "                 channels=CHANNELS,\n",
    "                 rate=RATE,\n",
    "                 input=True,\n",
    "                 start=False,\n",
    "                 # input_device_index=2,\n",
    "                 frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "\n",
    "got_a_sentence = False\n",
    "leave = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_int(sig, chunk):\n",
    "    global leave, got_a_sentence\n",
    "    leave = True\n",
    "    got_a_sentence = True\n",
    "\n",
    "\n",
    "def record_to_file(path, data, sample_width):\n",
    "    \"Records from the microphone and outputs the resulting data to 'path'\"\n",
    "    # sample_width, data = record()\n",
    "    data = pack('<' + ('h' * len(data)), *data)\n",
    "    wf = wave.open(path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(sample_width)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n",
    "\n",
    "\n",
    "def normalize(snd_data):\n",
    "    \"Average the volume out\"\n",
    "    MAXIMUM = 32767  # 16384\n",
    "    times = float(MAXIMUM) / max(abs(i) for i in snd_data)\n",
    "    r = array('h')\n",
    "    for i in snd_data:\n",
    "        r.append(int(i * times))\n",
    "    return r\n",
    "\n",
    "signal.signal(signal.SIGINT, handle_int)\n",
    "\n",
    "while not leave:\n",
    "    ring_buffer = collections.deque(maxlen=NUM_PADDING_CHUNKS)\n",
    "    triggered = False\n",
    "    voiced_frames = []\n",
    "    ring_buffer_flags = [0] * NUM_WINDOW_CHUNKS\n",
    "    ring_buffer_index = 0\n",
    "\n",
    "    ring_buffer_flags_end = [0] * NUM_WINDOW_CHUNKS_END\n",
    "    ring_buffer_index_end = 0\n",
    "    buffer_in = ''\n",
    "    # WangS\n",
    "    raw_data = array('h')\n",
    "    index = 0\n",
    "    start_point = 0\n",
    "    StartTime = time.time()\n",
    "    print(\"* recording: \")\n",
    "    stream.start_stream()\n",
    "\n",
    "    while not got_a_sentence and not leave:\n",
    "        chunk = stream.read(CHUNK_SIZE)\n",
    "        # add WangS\n",
    "        raw_data.extend(array('h', chunk))\n",
    "        index += CHUNK_SIZE\n",
    "        TimeUse = time.time() - StartTime\n",
    "\n",
    "        active = vad.is_speech(chunk, RATE)\n",
    "\n",
    "        sys.stdout.write('1' if active else '_')\n",
    "        ring_buffer_flags[ring_buffer_index] = 1 if active else 0\n",
    "        ring_buffer_index += 1\n",
    "        ring_buffer_index %= NUM_WINDOW_CHUNKS\n",
    "\n",
    "        ring_buffer_flags_end[ring_buffer_index_end] = 1 if active else 0\n",
    "        ring_buffer_index_end += 1\n",
    "        ring_buffer_index_end %= NUM_WINDOW_CHUNKS_END\n",
    "\n",
    "        # start point detection\n",
    "        if not triggered:\n",
    "            ring_buffer.append(chunk)\n",
    "            num_voiced = sum(ring_buffer_flags)\n",
    "            if num_voiced > 0.8 * NUM_WINDOW_CHUNKS:\n",
    "                sys.stdout.write(' Open ')\n",
    "                triggered = True\n",
    "                start_point = index - CHUNK_SIZE * 20  # start point\n",
    "                # voiced_frames.extend(ring_buffer)\n",
    "                ring_buffer.clear()\n",
    "        # end point detection\n",
    "        else:\n",
    "            # voiced_frames.append(chunk)\n",
    "            ring_buffer.append(chunk)\n",
    "            num_unvoiced = NUM_WINDOW_CHUNKS_END - sum(ring_buffer_flags_end)\n",
    "            if num_unvoiced > 0.90 * NUM_WINDOW_CHUNKS_END or TimeUse > 10:\n",
    "                sys.stdout.write(' Close ')\n",
    "                triggered = False\n",
    "                got_a_sentence = True\n",
    "\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    sys.stdout.write('\\n')\n",
    "    # data = b''.join(voiced_frames)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    print(\"* done recording\")\n",
    "    got_a_sentence = False\n",
    "\n",
    "    # write to file\n",
    "    raw_data.reverse()\n",
    "    for index in range(start_point):\n",
    "        raw_data.pop()\n",
    "    raw_data.reverse()\n",
    "    raw_data = normalize(raw_data)\n",
    "    record_to_file(\"recording.wav\", raw_data, 2)\n",
    "    leave = True\n",
    "\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2, sr2 = audiolib.load_wav_sample('ef.wav')\n",
    "size_s=0.03\n",
    "size= int(size_s * sr2)\n",
    "nsamples=len(a2)\n",
    "\n",
    "# a2 is array of int16, sr2 is sample rate 16000\n",
    "\n",
    "v=vad.create_vad()\n",
    "res=np.zeros((nsamples,))\n",
    "\n",
    "for i in range(size/2, nsamples-size/2):\n",
    "start = i-size/2\n",
    "end= i + size/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
